{
	"dag": {},
	"jobConfig": {
		"command": "glueetl",
		"description": "",
		"role": "arn:aws:iam::992382832162:role/GlueRole",
		"scriptName": "Transform.py",
		"version": "4.0",
		"language": "python-3",
		"scriptLocation": "s3://aws-glue-assets-992382832162-eu-north-1/scripts/",
		"temporaryDirectory": "s3://aws-glue-assets-992382832162-eu-north-1/temporary/",
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxRetries": 0,
		"metrics": true,
		"observabilityMetrics": true,
		"security": "none",
		"bookmark": "job-bookmark-disable",
		"logging": true,
		"spark": true,
		"sparkConfiguration": "standard",
		"sparkPath": "s3://aws-glue-assets-992382832162-eu-north-1/sparkHistoryLogs/",
		"serverEncryption": false,
		"glueHiveMetastore": true,
		"etlAutoScaling": false,
		"etlAutoTuning": false,
		"jobParameters": [],
		"tags": [],
		"connectionsList": [],
		"jobMode": "DEVELOPER_MODE",
		"name": "Transform",
		"pythonPath": null
	},
	"hasBeenSaved": false,
	"script": "import sys\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\nfrom awsglue.dynamicframe import DynamicFrame\r\nimport pyspark.sql.functions as F\r\nfrom pyspark.sql.functions import lit, col, from_unixtime, unix_timestamp, avg\r\nimport datetime\r\n\r\n# Initialize Spark and Glue Contexts\r\nsc = SparkContext.getOrCreate()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\n\r\n# Specify S3 bucket root path containing the hierarchy of Parquet files\r\ns3_root_path = \"s3://clickstream-ingest/clickstream/clickstream-raw/\"\r\n\r\n# Read all Parquet files in the specified S3 folder hierarchy into a Glue DynamicFrame\r\ndynamic_frame = glueContext.create_dynamic_frame.from_options(\r\n    connection_type=\"s3\",\r\n    connection_options={\"paths\": [s3_root_path], \"recurse\": True},\r\n    format=\"parquet\",\r\n    format_options={\"withHeader\": True}\r\n)\r\n\r\n# Convert the Glue DynamicFrame to a Spark DataFrame\r\ndf = dynamic_frame.toDF()\r\n\r\n# Convert bigint columns to timestamp\r\ndf = df.withColumn(\"session_start\", from_unixtime(col(\"session_start\") / 1000).cast(\"timestamp\"))\r\ndf = df.withColumn(\"click_timestamp\", from_unixtime(col(\"click_timestamp\") / 1000).cast(\"timestamp\"))\r\n\r\n# Remove nulls before aggregations\r\ndf = df.na.drop()\r\n\r\n# Distribution of Clicks\r\nenv_distribution = df.groupBy(\"click_environment\").count().withColumnRenamed(\"count\", \"click_count\")\r\ndevice_group_distribution = df.groupBy(\"click_deviceGroup\").count().withColumnRenamed(\"count\", \"click_count\")\r\nos_distribution = df.groupBy(\"operational_system\").count().withColumnRenamed(\"count\", \"click_count\")\r\n\r\n# Most and Least Popular Articles\r\npopular_articles = df.groupBy(\"click_article_id\").count().orderBy(\"count\", ascending=False)\r\nleast_popular_articles = df.groupBy(\"click_article_id\").count().orderBy(\"count\", ascending=True)\r\n\r\n# Most and Least Popular Categories\r\npopular_categories = df.groupBy(\"category_id\").count().orderBy(\"count\", ascending=False)\r\nleast_popular_categories = df.groupBy(\"category_id\").count().orderBy(\"count\", ascending=True)\r\n\r\n# Average Word Count per Article and Category\r\navg_word_count_per_article = df.groupBy(\"click_article_id\").agg(avg(\"words_count\").alias(\"avg_word_count\"))\r\navg_word_count_per_category = df.groupBy(\"category_id\").agg(avg(\"words_count\").alias(\"avg_word_count\"))\r\n\r\n# Average Time to Click on Article\r\ndf = df.withColumn(\"time_to_click\", col(\"click_timestamp\").cast(\"long\") - col(\"session_start\").cast(\"long\"))\r\navg_time_to_click_per_category = df.groupBy(\"category_id\").agg(avg(\"time_to_click\").alias(\"avg_time_to_click\"))\r\n\r\n# Function to save each insight as a separate CSV with timestamp\r\ndef save_insight(df, insight_name):\r\n    file_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\r\n    output_path = f\"s3a://test-lambda-insert/clickstream/clickstream-insights/{insight_name}/{insight_name}_{file_timestamp}.csv\"\r\n    df.coalesce(1).write.csv(output_path, mode='overwrite', header=True)\r\n\r\n# Save each insight\r\nsave_insight(env_distribution, \"env_distribution\")\r\nsave_insight(device_group_distribution, \"device_group_distribution\")\r\nsave_insight(os_distribution, \"os_distribution\")\r\nsave_insight(popular_articles, \"popular_articles\")\r\nsave_insight(least_popular_articles, \"least_popular_articles\")\r\nsave_insight(popular_categories, \"popular_categories\")\r\nsave_insight(least_popular_categories, \"least_popular_categories\")\r\nsave_insight(avg_word_count_per_article, \"avg_word_count_per_article\")\r\nsave_insight(avg_word_count_per_category, \"avg_word_count_per_category\")\r\nsave_insight(avg_time_to_click_per_category, \"avg_time_to_click_per_category\")\r\n"
}